{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization**  \n",
    "말뭉치(corpus)에서 토큰 단위로 나누는 작업"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 단어 토큰화**  \n",
    "토큰의 기준을 단어로 설정  \n",
    "\n",
    "nltk.tokenize 의 word_tokenize나 WordPuncthTokenizer를 활용하여 토큰화를 시킬 수 있다\n",
    "\n",
    "하지만 말뭉치의 어느부분까지를 토큰의 기준으로 세우는가 등 차이가 생길 수 있다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 토큰화에서 고려해야할 사항**\n",
    "\n",
    "1) 구두점이나 특수문자를 단순 제외해서는 안된다  \n",
    "\n",
    "2) 줄임말과 단어 내에 띄어쓰기가 있는 경우  \n",
    "\n",
    "해당 사항을 고려한 방법으로 TreebankWordTokenizer가 있다  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 문장 토큰화**  \n",
    "토큰의 기준을 문장으로 설정  \n",
    "\n",
    "문장의 기준을 단순히 .이나 !로 할 수도 없음\n",
    "ex) gamil.com 등  \n",
    "\n",
    "사용하는 말뭉치가 어떤 국적의 언어인지, 어떤 종류의 말뭉치인지를 보고 직접 규칙을 정의해볼 수 있다\n",
    "\n",
    "영어 문장의 토큰화로는 sent_tokenize가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d59506fa9a7e01e2699370be2fe0612db2da9f140da73fde608cb90a056765fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
